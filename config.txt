# common params

eps = 1e-7
max_iter = 40
seed = 445
num_threads = -1

# kmeans params

num_clusters = 30#150
kmeans_max_iter = 50

# anchor params

max_threads = 0
new_dim = 1000

# data params

data_dir = datasets
load_data = 2 #uci # 1, uci - uci format, 2 - random, 3 - halfmodel, 4 - diagonal with T
data_name = nips
matrices_names = Phi_nips Theta_nips
alpha = 0.8
gen_name = 0_1_100_16_500

# methods params

# for gradient descent
grad_desc_alpha = 1
grad_desc_alpha_step = 0.8

# for cnmf
cnmf_alpha = 0.1
cnmf_beta = 0.21

# matrix parameters

#gen_phi = gen_matrix_topic
gen_phi = gen_matrix_sparse
gen_theta = gen_matrix_sparse
gen_documents = 1
real_phi_sparsity = 0.1
real_theta_sparsity = 0.5#0.3
phi_sparsity = 0.04
theta_sparsity = 0.3#0.3

phi_init = gen_matrix_sparse
theta_init = gen_matrix_sparse

N = 2000 # number of words
M = 500 # number of documents
T_0 = 20 # "real" number of topics
T = 30 # number of topics

# topic matrix params

nnoise = 2
nkernel = 25
#shift = 5

# experiments params

#experiment = nips_30_T25_conv_p10
experiment = plsa
#experiment = test_time
prepare = 0 # -1 --- no preparation
prepare_method = 1, 2, 3, 4, 5 #array connected to runs
compare_prepare = 0
compare_methods = 0
T_begin = 5
T_end = 100
T_step = 5
run_info = 1 # none(0), results(1), run(2)
runs = 15, 15, 15, 1, 10# times to run the experiments
schedule = plsa #als,hals,mult,plsa # schedule of methods (no spaces); all methods in methods.py
measure = frobenius,rmse,perplexity # measures to produce; all methods in measure.py
finals = mean_pmi,mean_max_pmi,mean_hell,mean_nhell,min_nhell
compare_real = 1 # compare with real matrices 0, 1
munkres = 1
normalize_iter = 1 # iteration on what to apply normalization
save_results = 0
save_file = results.txt
save_matrices = 0, 0, 0, 0, 0 #array for every prepare_method
show_results = 0
save_topics = 0
result_dir = test/05_04_16_random_new_hell/
save_results = 0
prepare = 0

begin_graph_iter = 1