# common params

eps = 10e-7 ####10e-7
max_iter = 50
seed = 898#444
num_threads = -1

# kmeans params

num_clusters = 70#150
kmeans_max_iter = 50

# anchor params

max_threads = 8###0
new_dim = 1500 #must change for real collections!!!!

# data params

data_dir = datasets
load_data = 4 #uci # 1, uci - uci format, 2 - random, 3 - halfmodel, 4 - diagonal with T
data_name = nips
alpha = 1.0
gen_name = 0_1_100_16_500

# methods params

# for gradient descent
grad_desc_alpha = 1
grad_desc_alpha_step = 0.8

# matrix parameters

gen_phi = gen_matrix_sparse
gen_theta = gen_matrix_sparse
gen_documents = 1
real_phi_sparsity = 0.5#0.5
real_theta_sparsity = 0.1 #0.6
phi_sparsity = 0.05
theta_sparsity = 0.1

phi_init = gen_matrix_sparse
theta_init = gen_matrix_sparse

N = 10 # number of words
M = 10 # number of documents
T_0 = 70 # "real" number of topics
T = 70 # number of topics

# topic matrix params

nnoise = 2
nkernel = 25
#shift = 5

# experiments params

experiment = plsa
prepare = 0 # -1 --- no preparation
prepare_method = 1,9#1,3,4,7,8#array connected to runs
compare_prepare = 0
compare_methods = 0
#T_begin = 5
#T_end = 100
#T_step = 5
run_info = 1 # none(0), results(1), run(2)
runs = 10,10#10,10,10,10,10#times to run the experiments
schedule = plsa #als,hals,mult,plsa # schedule of methods (no spaces); all methods in methods.py
measure = perplexity,hellinger # measures to produce; all methods in measure.py
finals = mean_pmi,mean_nhell#mean_max_pmi,mean_hell,mean_nhell,min_nhell
compare_real = 0 # compare with real matrices 0, 1
munkres = 1
save_results = 0
save_file = results.txt
save_matrices = 0, 0, 0, 0, 0, 0, 0, 0 #array for every prepare_method
show_results = 0
save_topics = 0
result_dir = test/diag_arora_uniform/
jogging = 1
begin_graph_iter = 0
